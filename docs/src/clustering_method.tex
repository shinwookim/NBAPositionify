\documentclass[./main.tex]{subfiles}
\begin{document}
\subsection{Clustering}\label{subsec:clustering}
Clustering is a data mining technique meant to group similar data points together into groups, or clusters. Given the nature of our goal being to group players within their positions (i.e., to find similarities between players who are in certain positions), clustering was an avenue which we saw as having potential for identifying and confirming what attributes best determine player position. Further, these clusters could give us a good sense of outliers to these normal trends seen. For instance, if a player who is a small forward is classified within the point guard cluster, this player could be seen as an outlier.

Two clustering algorithms were chosen to run experiments on: \textbf{K-Means} and \textbf{Agglomerative} clustering. We chose K-Means as a baseline algorithm, with the underlying assumption that players with certain relative stats would be close to one another if they play the same position. Having ``centroids'' representing the position groups seems to be a solid foundational baseline for determining what group players belong in. Agglomerative clustering was chosen as an alternative given the nature of positions in basketball becoming relatively more fluid in recent years. Agglomerative clustering is hierarchical in the sense that it starts with one large cluster, and narrows itself down into smaller, more distinct clusters with each clustering iteration. We want to see how similar players of similar positions are, while also finding distinct groups for them. We found agglomerative clustering to be successful in accomplishing this task and giving us another clustering perspective.

To best determine how many clusters to group our data in, we used as our metric Within Cluster Sum-Of-Squares (WCSS) which determines how close together the points within a cluster are; a lower WCSS value means more tightly packed clusters. We ran $k$-means clustering on 1 through 5 clusters in separate iterations to determine the amount of clusters which would be optimal, which we then used to perform our experiments and analysis for both k-means and agglomerative.

A subset of features was chosen from the dataset to perform the k-means clustering to maximize the likelihood of identifying a correlation between cluster and position. This subset contained the most important features found for determining position from our feature analysis. Any column which had more than a 5\% relation to position was included for clustering. Features included in the subset were \textit{total rebound percentage}, \textit{total assist percentage}, \textit{height} and \textit{weight}. Data normalization was also to be performed before clustering, where each of the features chosen to train the clustering on would be subtracted by the column's mean and then divided by the standard deviation. This made it so that all the different features, despite them containing different values and being within different ranges, were on similar scales.
\end{document}